Rule 1.5.0.8 Type Determines Optimization Opportunities

5.1 Basic Types

- C has a series of basic types and some means of constructing derived types from them that we will describe later in Section 6. 

Rule 1.5.0.1

- All basic values in C are numbers, but there are numbers of different kind.
- Two different classes of numbers with two subclasses: 
	- unsigned integers, signed integers, real floating point numbers, and complex floating point numbers. s
- These numbers vary based on precision

Rule 1.5.1.2 
- Use size_t for sizes, cardinalities or ordinal numbers 

Rule 1.5.1.3
- Use 'unsigned' for small quantities that can't be negative. 
	- If your program really needs values that may both be positive and negative but don't have fractions, use a signed type, see section 5.5.5.

Rule 1.5.1.4 
- Use 'signed' for small quantities that bear a sign. 

Rule 1.5.1.5 
- Use ptrdiff_t for large differences that bear a sign 
	- if you want to do fractional computation with avalues such as 0.5 or 3.77189E+89 use floating point types, see section 5.5.7

Rule 1.5.1.6
- Use 'double' for floating point calculations

Rule 1.5.1.7
- Use 'double complex' for complex calculations 


5.2: Specifying Values 
- how 'literals' can be specified: 
	123 - decimal integer constant - the most natural choice for most of us

	077 - octal integer constant - this is specified bty a sequence of digits, the first being 0 nad the following between 0 and 7 e.g 077 has the value 63. There is only one octal literal that is commonly used, namely 0 itself. 
	
	0xFFFF - hexadecimal integer constant : this is specified by a start of 0x followed by a sequence of digits between 0.....9, a....f e.g. 0xbeaf is value 48815. The a....f and x can also be written in capitals, 0XBEAF

	1.7E-13 - decimal floating point constants : similar to regular decimal points - except with a scientific notation added with an exponent. mEe is interpreted as m * 10^e

	0x1.7aP-13 - hexadecimal floating point constants - Usually used to describe floating point values in a form that will ease to specify values that have exact representations. The general form 0xhPe is interpreted as h * 2^e. Here h is specified as an hexadecimal fraction. The exponent e is still specified as a decimal number. 

	'a' - integer character constant : Theses are characters put into ' apostrophs, such as 'a' or '?' . These have values that are only implicitly fixed by the C standard e.g. 'a' corresponds to the integer code for the character "a" of the Latin alphabet. 
		- Inside character constants a "\" character has a special meaning e.g. we already seen '\n' for the newline character.

	"hello" - string literals : They specify text e.g. as we needed it for the 'printf' and 'puts' functions. Again the "\" character is special as in character constants. 

	Rule 1.5.2.1 
	- Consecutive string literals are concatenated 
		- For numerical literals, the first rule is: 

	Rule 1.5.2.2 
	- Numerical literals are never negative 
		- that is if wwe write something like -34 or -1.5E-23, the leading sign is not considered part of the number but is the 'negation' operator applied to the number that comes after. We will see below where this is important. Bizarre as this may sound, the minus sign in the exponent is considered to be part of a floating point literal. 

	Rule 1.5.2.3
	- Decimal integer constants are signed 

		- This is an important feature, we'd probably expect the expression -1 to be a signed, negative value. 
		- To determine the exact type for integer literals we always have a "first fit" rule. For decimal integers this reads: 

	Rule 1.5.2.4
	- A decimal integer constant has the first of the 3 signed types that fits it 
		- The rule can have surprising effects. Suppose that on a platform the minimal 'signed' value is -2^15 = -32768 and the maximumm value is 2^15 - 1 = 32767. The constant 32768 then doesn't fit into 'signed' and is thus 'signed long'. As a consequence the expression -32768 has type 'signed long'. Thus the minimal value of the type 'signed' on such a platform cannot be written as a literal constant.

	Rule 1.5.2.5
	- The same value can have different types
		- Deducing the type of an octal or hexadecimal constant is a bit more complicated. These can also be of an 'unsigned' type if the value doesn't fit for a 'signed' one. In our example above, the hexadecimal constant 0x7FFF has the value 32767 and thus type 'signed'. Other than for the decimal constant 0x8000(value 32768 written in hexadecimal) then is an 'unsigned' and expression -0x8000 again is 'unsigned'.

	Rule 1.5.2.6
	- Don't use octal or hexadecimal constants to express negative values.
		- Or if we formulate it positively 
	Rule 1.5.2.7
	- Use decimal constants to express negative values
		- Integer constants can be forced to be 'unsigned' or to be of a type of minimal width. This is done by appending "U", "L" or "LL" to the literal. e.g. 1U has value 1 and type 'unsigned', 1L is 'signed long' and 1UL has the same value but type 'unsigned long long'


	Table 8: Refer to table (c_stuff folder) constants_and_types

	Note: 
	- a common error is to try to assign a hexadecimal constant to a 'signed' under the expectation that it will represent a negative value. Consider a declaration such as int x = 0xFFFFFFFF. This is done under the assumption that the hexadecimal value has the same binary representation as the signed value -1. On most architectures with 32 bit signed this will be true(but not all of them) but then nothing guarantees that the effective value +4294967295 is converted to the value -1.

	- You remember that value 0 is important. It is so important that it has a lot of equivalent spellings: 0, 0x0 and '\0' are all the same value, a 0 of type 'signed int'. 0 has no decimal integer spelling: 0.0 is a decimal spelling for the value 0 but seen as a floating point value namely with the type 'double'

	Rule 1.5.2.8
	- Different literals can have the same value
		- For integers this rule looks almost trivial, for floating point constants this is less obvious. Floatingy point values are only an approximation of the value they present literally, because binary digits of the fractional part may be truncated or rounded. 

	Rule 1.5.2.9
	- The effective value of a decimal floating point constant may be different from its literal value. 


	
	Rule 1.5.5.6
	- Positive values are represented independently from signedness.
		- A positive value with a signed tupe has the same representation as in the corresponding unsigned type. That is the reason why we were able to express Rule 1.5.5.3 for all integer types. These also have a precision, p that determines the maximum value of the type.

		- The next thing that the standard prescribes is that signed types have exactly one additional bit, the 'sign bit'. If it is 0 we have a positive value, if it is 1 the value is negative. Unfortunately, there are different concepts how such a sign can be used to obtain a negative number. C allows three different 'sign representations' 
			- sign and magnitude
			- ones' complement 
			- two's complement 

		- The first two nowadays probably only have historic or exotic relevance: for sign and magnitude, the magnitude is taken as for positive values, and the sign bit simple specifies that there is a minus sign. Ones' complement takes the corresponding positive value and complements all bits. Both representations have the disadvantage that two values evaluate to 0, there is a positive and negative 0.

		- Commonly used on modern platforms is the two's complement representation. It performs exactly the same arithmetic as we have already seen for unsigned types, only that the upper half of the unsigned values is interpreted as being negative. The following two functions are basically all that is needed to interpret unsigned values as signed ones. 

		```c

			bool is_negative(unsigned a) { unsigned const int_max = UINT_MAX /2; return a > int_max;
			}
			bool is_signed_less(unsigned a, unsigned b) {
			if (is_negative(b) && !is_negative(a)) return false; else return a < b;
			}

		```

		- When realized like that, signed integer arithmetic will again behave more or less nicely. Unfortunately, there is a pitfall that makes the outcome of signed arithmetic difficult to predict: Overflow.
		Where unsigned values are forced to wrap around, the behaviour of a signed overflow is 'undefined'. The following two loops look quite the same: 

		```c

		for (unsigned i = 1; i; ++i) do_something();


		```

		```c

		for ( signed i = 1; i; ++i) do_something();s

		```

		- We know what happens for the first one: the counter is incremented up to UINT_MAX then wraps around to 0. All of this may take some time, but after UINT_MAX-1 iterations the loop stops because i will have reached 0.

		- For the second, all looks similar. But because here the behaviour of overflow is undefined the compiler is allowed to pretend that it will never happen. Since it also knows that the value at start is positive it may assume that i, as long as the program has defined behaviour, is never negative or 0. The as-if "RULE 1.5.0.7" allows it to optimize the second loop to: 

		```c

		while (true) do_something();

		```

		- That's right, an infinite loop. This is a general feature of undefined behaviour is C code: 

	Rule 1.5.5.7
	- Once the abstract state machine reaches an undefined state no further assumption about the continuation of the execution can be made.
		- Not only that the compiler is allowed to do what pleases for the operation itself("undefined? so let's define it"), but it may also assume that it will never reach such a state and draw conclusions from that. 

	Rule 1.5.5.8 
	- It is your responsibility to avoid undefined behaviour of all operations. 

		- What makee things even worse is that one some platforms with some standard compiler options all will just look right. Since the behaviour is undefined, on a given platform signed integer arithmetic might turn out basically the same as unsigned. But changing the platform, the compiler or just some options can change that. All of a sudden your program that worked for years crashes out of nowhere. Basically what we discussed up to this section always had well defined behaviour, so the abstract state machine is always in a well defined state. Signed arithmetic changes this, so as long as you musn't avoid it.

	Rule 1.5.5.9
	- Signed arithmetic may trap badly
		- One of the things that might already overflow for signed types is negation. We have seen above that INT_MAX has all bits but the sign bit set to 1. INT_MIN has then the 'next' representation, namely the sign bit set to 1 and all other values set to 0. The corresponding value is not -INT_MAX

		We then have:

	Rule 1.5.5.10
	- In twos' complement representation INT_MIN < -INT_MAX
		- Or stated otherwise, in twos' complement representation the positive value -INT_MIN is out of bounds since the value of the operation is larger than INT_MAX.

	Rule 1.5.5.11
	- Negation may overflow for signed arithmetic
		- For signed types, bit operations work with the binary representation. In fact bit operations even allow to detect the sign representation. 

		
